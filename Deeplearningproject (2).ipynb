{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocoQkPYrkoI9",
        "outputId": "37428158-a1a4-4a02-91e8-85d4067b79ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/project/miniImageNet'\n",
        "train_set = torchvision.datasets.ImageFolder(root=os.path.join(dataset_path, 'train'), transform=transform)\n",
        "val_set = torchvision.datasets.ImageFolder(root=os.path.join(dataset_path, 'val'), transform=transform)\n",
        "test_set = torchvision.datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(train_set.classes))\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "\n",
        "train_model(model, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "\n",
        "project_folder = '/content/drive/MyDrive/project'\n",
        "model_save_path = os.path.join(project_folder, 'resnet18_miniImageNet.pth')\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "\n",
        "print(f\"Model saved to: {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzDgiyc9kuvv",
        "outputId": "825caa25-6267-4d65-d75a-4a267b65e424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 172MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.3128431661219537\n",
            "Epoch 2/5, Loss: 0.8590132582791244\n",
            "Epoch 3/5, Loss: 0.610519960220856\n",
            "Epoch 4/5, Loss: 0.4343314125002185\n",
            "Epoch 5/5, Loss: 0.32685659160908265\n",
            "Model saved to: /content/drive/MyDrive/project/resnet18_miniImageNet.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.img_labels = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "        self.img_labels.sort()\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.labels = list(set(file_name.split('_')[0] for file_name in self.img_labels))\n",
        "        self.label_to_index = {label: index for index, label in enumerate(self.labels)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.folder_path, self.img_labels[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.img_labels[idx].split('_')[0]\n",
        "        label_index = self.label_to_index[label]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label_index\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = SimpleDataset('/content/drive/My Drive/project/EuroSAT/trainset', transform=transform)\n",
        "test_dataset = SimpleDataset('/content/drive/My Drive/project/EuroSAT/testset', transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "\n",
        "pretrained_dict = torch.load('/content/drive/My Drive/project/resnet18_miniImageNet.pth', map_location=device)\n",
        "\n",
        "\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if 'fc' not in k}\n",
        "\n",
        "\n",
        "model.load_state_dict(pretrained_dict, strict=False)\n",
        "\n",
        "\n",
        "model.fc = nn.Linear(num_ftrs, len(train_dataset.labels))\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def fine_tune_model(model, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "\n",
        "fine_tune_model(model, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n",
        "\n",
        "\n",
        "model_save_path = '/content/drive/My Drive/project/resnet18_EuroSAT.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Fine-tuned model saved to: {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TnfUS-7UEBs",
        "outputId": "cbe7209e-f818-4c37-e161-30ec09be704b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.8507752418518066\n",
            "Epoch 2/5, Loss: 0.757851779460907\n",
            "Epoch 3/5, Loss: 0.34761515259742737\n",
            "Epoch 4/5, Loss: 0.14797437191009521\n",
            "Epoch 5/5, Loss: 0.061268970370292664\n",
            "Accuracy of the model on the test images: 86.66666666666667%\n",
            "Fine-tuned model saved to: /content/drive/My Drive/project/resnet18_EuroSAT.pth\n"
          ]
        }
      ]
    }
  ]
}